# app.py íŒŒì¼ ë‚´ì— ì •ì˜

import streamlit as st
from openai import OpenAI
import json
import os
from dotenv import load_dotenv

# app.py íŒŒì¼ ìƒë‹¨ (importë¬¸ ë°”ë¡œ ì•„ë˜)

# from dotenv import load_dotenv # ì´ ë¼ì¸ì€ Streamlit Cloudì—ì„œëŠ” ì£¼ì„ ì²˜ë¦¬í•˜ê±°ë‚˜ ì œê±°í•´ì•¼ í•©ë‹ˆë‹¤.

# --- LLM í´ë¼ì´ì–¸íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜ ---
@st.cache_resource

def get_openai_client():
    # Streamlit Cloudê°€ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•œ í›„ ì´ í•¨ìˆ˜ê°€ ì‹¤í–‰ë©ë‹ˆë‹¤.
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        st.error("ì˜¤ë¥˜: API í‚¤ (OPENAI_API_KEY)ê°€ Streamlit Secretsì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop() # í‚¤ê°€ ì—†ìœ¼ë©´ ì•± ì‹¤í–‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.
        
    return OpenAI(api_key=api_key)

# app.py íŒŒì¼ì— ì¶”ê°€í•´ì•¼ í•  run_master_agent í•¨ìˆ˜

def run_master_agent(user_prompt: str, location: str, structure_name: str):
    
    # 1. ì•ˆì „í•˜ê²Œ ì´ˆê¸°í™”ëœ í´ë¼ì´ì–¸íŠ¸ ê°ì²´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    client = get_openai_client()
    
    # 2. Tool í•¨ìˆ˜ë“¤ê³¼ LLMì´ ì‚¬ìš©í•  ë³€ìˆ˜ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.
    available_functions = {
        "get_heritage_text_record": get_heritage_text_record,
        "call_3d_restoration_api": call_3d_restoration_api,
    }
    # (ì£¼ì˜: toolsëŠ” íŒŒì¼ ìƒë‹¨ì— ì •ì˜ëœ ì „ì—­ ë³€ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.)
    
    messages = [{"role": "user", "content": user_prompt}]
    tool_results = {}
    
    # 3. LLMê³¼ Tools ê°„ì˜ ëŒ€í™” ë£¨í”„ (ìµœëŒ€ 3íšŒ ë°˜ë³µ)
    for _ in range(3):
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            tools=tools,
            tool_choice="auto",
        )
        
        response_message = response.choices[0].message
        
        # ìµœì¢… ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸ê°€ ë‚˜ì™”ëŠ”ì§€ í™•ì¸
        if not response_message.tool_calls:
            return response_message.content, tool_results
        
        # 4. Tool Call ì‹¤í–‰ (MCP í•µì‹¬ ë¡œì§)
        messages.append(response_message)
        
        for tool_call in response_message.tool_calls:
            function_name = tool_call.function.name
            function_args = json.loads(tool_call.function.arguments)
            
            st.info(f"ì—ì´ì „íŠ¸ê°€ ì™¸ë¶€ ë„êµ¬ í˜¸ì¶œ: {function_name}")
            
            # í•¨ìˆ˜ ì‹¤í–‰
            if function_name == "get_heritage_text_record":
                function_args['location'] = location
                function_args['structure_name'] = structure_name
            
            function_response = available_functions[function_name](**function_args)
            
            # 5. Tool ì‹¤í–‰ ê²°ê³¼ë¥¼ ì €ì¥í•˜ê³  LLMì—ê²Œ ì „ë‹¬í•˜ì—¬ ìµœì¢… ì‘ë‹µì„ ìœ ë„
            tool_results[function_name] = json.loads(function_response)
            messages.append(
                {"tool_call_id": tool_call.id, "role": "tool", "content": function_response}
            )
            
    # ë£¨í”„ ì¢…ë£Œ í›„ ìµœì¢… ì‘ë‹µ ë°˜í™˜
    final_response = client.chat.completions.create(model="gpt-4o-mini", messages=messages)
    return final_response.choices[0].message.content, tool_results

# --- Streamlit UI ì‹œì‘ --- (run_master_agent í•¨ìˆ˜ ì •ì˜ ë’¤ì— ìœ„ì¹˜)

st.title("ğŸŒ ì§€ì—­ ë¬¸í™”ìœ ì‚° ë””ì§€í„¸ ë§ˆìŠ¤í„° ì—ì´ì „íŠ¸")
st.markdown("ì—­ì‚¬ ê¸°ë¡ì„ ë¶„ì„í•˜ê³  í›¼ì†ëœ ë¬¸í™”ìœ ì‚°ì„ ë””ì§€í„¸ë¡œ ë³µì›í•©ë‹ˆë‹¤.")
with st.sidebar:
    st.header("ë¬¸í™”ìœ ì‚° ì •ë³´ ì…ë ¥")
    location = st.text_input("ì§€ì—­:", "ì„œìš¸ ì¢…ë¡œ")
    structure_name = st.text_input("ë¬¸í™”ìœ ì‚° ì´ë¦„/íŠ¹ì§•:", "ê²½ë³µê¶ ì‚¬ì •ì „")
    location_data = st.text_input("ì§€í˜• ë°ì´í„°:", "í‰ì§€")
    
    prompt = st.text_area(
        "AI ë¶„ì„ ë° ë³µì› ìš”ì²­:", 
        f"'{structure_name}'ì˜ ì—­ì‚¬ ê¸°ë¡ì„ ê²€ìƒ‰í•˜ê³ ...",
        height=150
    )

# ì‚¬ì´ë“œë°” (ì…ë ¥ ì˜ì—­)
with st.sidebar:
    st.header("ë¬¸í™”ìœ ì‚° ì •ë³´ ì…ë ¥")
    # ... (st.text_input, st.text_area ë“±ì˜ ì…ë ¥ ìœ„ì ¯ ì½”ë“œ)
    
# ë©”ì¸ ì‹¤í–‰ ë²„íŠ¼
if st.button("ğŸ” ë¶„ì„ ë° ë³µì› ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰"):
    # ì´ ì•ˆì—ëŠ” run_master_agent(prompt, ...) í˜¸ì¶œ ì½”ë“œë§Œ ìˆì–´ì•¼ í•¨
    # ...

# client = get_openai_client() # ì´ì œ ì´ client ê°ì²´ëŠ” í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•´ì„œ ì–»ìŠµë‹ˆë‹¤.

# OpenAI API í‚¤ëŠ” í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œë©ë‹ˆë‹¤.

# --- 1. Tool(Function) ì •ì˜: Mock ë°ì´í„° ë° API ëŒ€ì²´ í•¨ìˆ˜ ---

def get_heritage_text_record(location: str, structure_name: str) -> str:
    """
    íŠ¹ì • ì§€ì—­ê³¼ êµ¬ì¡°ë¬¼ì˜ ì´ë¦„ì„ ê¸°ë°˜ìœ¼ë¡œ ë¬¸í™”ìœ ì‚° í¬í„¸ì—ì„œ ê´€ë ¨ ì—­ì‚¬ ê¸°ë¡ í…ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    # ì‹¤ì œ êµ¬í˜„ ì‹œ: ê³µê³µë°ì´í„°í¬í„¸ì˜ ë¬¸í™”ì¬ ì •ë³´ë¥¼ í˜¸ì¶œí•˜ëŠ” requests ì½”ë“œê°€ ë“¤ì–´ê°‘ë‹ˆë‹¤.
    if "ê²½ë³µê¶ ì‚¬ì •ì „" in structure_name:
        return json.dumps({
            "status": "success",
            "text_record": "ì‚¬ì •ì „ì€ ê²½ë³µê¶ì˜ ì •ì „ìœ¼ë¡œ, ì„ê¸ˆì˜ ì§‘ë¬´ì‹¤ì´ì—ˆë‹¤. 1917ë…„ í™”ì¬ë¡œ ì†Œì‹¤ë˜ì—ˆìœ¼ë‚˜, ê¸°ë¡ì— ë”°ë¥´ë©´ í™”ë ¤í•œ ë‹¨ì²­ê³¼ ìš©ë§ˆë£¨ê°€ íŠ¹ì§•ì ì´ì—ˆìœ¼ë©°, ë‚´ë¶€ì—ëŠ” ì˜¨ëŒë°©ì´ ìˆì—ˆë‹¤. ì£¼ë³€ì—ëŠ” íšŒë‘ì´ ìˆì—ˆë‹¤.",
            "original_image_url": "https://example.com/damaged_original.jpg" # ì›ë³¸ ì´ë¯¸ì§€ URL (ê°€ì •)
        })
    return json.dumps({"status": "error", "text_record": "ê´€ë ¨ ê¸°ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."})

def call_3d_restoration_api(description: str, location_data: str) -> str:
    """
    ìƒì„¸í•œ ë³µì› ë¬˜ì‚¬(description)ì™€ ì§€ë¦¬ ì •ë³´(location_data)ë¥¼ ë°›ì•„ 3D ëª¨ë¸ë§ ë˜ëŠ” ë³µì› ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ì™¸ë¶€ AI APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    """
    # ì‹¤ì œ êµ¬í˜„ ì‹œ: 3D ëª¨ë¸ë§ API (ì˜ˆ: Blender API ë˜í¼, ë˜ëŠ” DALL-E/Midjourneyì˜ ê³ ê¸‰ í”„ë¡¬í”„íŠ¸) í˜¸ì¶œ ì½”ë“œê°€ ë“¤ì–´ê°‘ë‹ˆë‹¤.
    print(f"3D ë³µì› API í˜¸ì¶œ ì¤‘. ë¬˜ì‚¬: {description[:50]}...")
    
    # Mock ë³µì› ê²°ê³¼ URL ë°˜í™˜
    return json.dumps({
        "status": "success", 
        "restored_url": "https://example.com/restored_model_placeholder.jpg" 
    })

# LLMì—ê²Œ ì œê³µí•  ìµœì¢… Tool ìŠ¤í‚¤ë§ˆ ëª©ë¡
tools = [
    # get_heritage_text_record ìŠ¤í‚¤ë§ˆ ì •ì˜ (ì´ì „ ì˜ˆì‹œì™€ ìœ ì‚¬í•˜ê²Œ)
    {
        "type": "function",
        "function": {
            "name": "get_heritage_text_record",
            "description": "ì§€ì—­ ë° êµ¬ì¡°ë¬¼ ì´ë¦„ì„ ì‚¬ìš©í•˜ì—¬ ì—­ì‚¬ ê¸°ë¡ í…ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰í•˜ê³  ì›ë³¸ ì´ë¯¸ì§€ URLì„ ë°˜í™˜í•©ë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {"type": "string", "description": "ë¬¸í™”ìœ ì‚°ì´ ìœ„ì¹˜í–ˆë˜ ì§€ì—­"},
                    "structure_name": {"type": "string", "description": "ë¬¸í™”ìœ ì‚°ì˜ ì´ë¦„ ë˜ëŠ” íŠ¹ì§•"},
                },
                "required": ["structure_name"],
            },
        },
    },
    # call_3d_restoration_api ìŠ¤í‚¤ë§ˆ ì •ì˜
    {
        "type": "function",
        "function": {
            "name": "call_3d_restoration_api",
            "description": "ìƒì„¸í•œ ë¬˜ì‚¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 3D ëª¨ë¸ ë˜ëŠ” ë³µì› ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” APIë¥¼ í˜¸ì¶œí•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "description": {"type": "string", "description": "ë³µì›í•  êµ¬ì¡°ë¬¼ì˜ ìƒì„¸í•œ ì‹œê°ì  ë¬˜ì‚¬"},
                    "location_data": {"type": "string", "description": "ì§€ë¦¬ ì •ë³´, ì§€í˜•ì  íŠ¹ì§• (ì˜ˆ: ê²½ì‚¬ì§„ ì–¸ë• ìœ„, ê°• ì˜†)"},
                },
                "required": ["description", "location_data"],
            },
        },
    },
]

available_functions = {
    "get_heritage_text_record": get_heritage_text_record,
    "call_3d_restoration_api": call_3d_restoration_api,
}
